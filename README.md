# Data-Camp-Projects <br/><br/><br/>

## [Cleaning an Orders Dataset with PySpark Project](https://github.com/zaid638/Data-Camp-Projects/tree/main/Cleaning%20an%20Orders%20Dataset%20with%20PySpark%20Project) <br/><br/>

In this project, I work with e-commerce company and used PySpark,  for data processing, to clean an orders dataset. <br/><br/>

### Objective <br/><br/>

* I have been requested by a peer Machine Learning team to clean the data containing the information about orders made last year. They are planning to further use this cleaned data to build a demand forecasting model. To achieve this, they have shared their requirements regarding the desired output format. <br/><br/>
--- <br/><br/>

## [Building a Retail Data Pipeline Project](https://github.com/zaid638/Data-Camp-Projects/tree/main/Building%20a%20Retail%20Data%20Pipeline%20Project) <br/><br/>

In this project, I have been tasked with creating a data pipeline for the analysis of supply and demand around the holidays, along with conducting a preliminary analysis of the data. You will be working with two data sources: grocery sales and complementary data. You have been provided with the `grocery_sales` table in `PostgreSQL` database. Also, you have the `extra_data.parquet` file that contains complementary data.<br/><br/>

### Objective <br/><br/>

* Need to merge those files and perform some data manipulations.<br/>
* Store the transformed DataFrame as the `clean_data` variable containing the specific columns.<br/>
* Analyze monthly sales and store the results of analysis as the `agg_data` variable.<br/>
* Save the `clean_data` and `agg_data` as the csv files. <br/><br/>

![ETL Pipeline](https://github.com/zaid638/Data-Camp-Projects/blob/main/Building%20a%20Retail%20Data%20Pipeline%20Project/Retail_ETL_Diagram.png) <br/><br/>
--- <br/><br/>

## [Performing a Code Review Project](https://github.com/zaid638/Data-Camp-Projects/tree/main/Performing%20a%20Code%20Review%20Project) <br/><br/>

In this project, I worked with a procurement team, who is trying to decide the best new mobile phone to offer to thier university's employees. Other data team has been developing a workflow to help provide insight to the procurement team. I reviewed their code to ensure it's ready to ship to production. <br/><br/>

### Objective <br/><br/>

* Review the function to prepare smartphone data from a CSV file for visualization. <br/>
* Refactor the code appropriately. <br/>
* Re-work unit test to ensure that it matches the transformation logic in the function. <br/>
* Ensure that unit tests execute with `ExitCode.OK`. <br/><br/>
--- <br/><br/>

## [Audible Data Cleaning Using Python Project](https://github.com/zaid638/Data-Camp-Projects/tree/main/Audible%20Data%20Cleaning%20Using%20Python%20Project) <br/><br/>

In this project, I worked with a dataset of audiobooks downloaded from audible.in from 1998 to 2025 (pre-planned releases). [Source](https://www.kaggle.com/datasets/snehangsude/audible-dataset) <br/><br/>

### Objective <br/><br/>

* Loading and Inspecting the Data.<br/>
* Clean text data in Author and Narrator columns. <br/>
* Extract number of stars and ratings from Stars column. <br/>
* Change data types. <br/>
* Extract hours and minutes from the `time` column. <br/>
* Check data ranges. <br/>
* Checking for duplicates. <br/>
* Dealing with missing data. <br/>
* Save the cleaned data set. <br/><br/>
--- <br/><br/>

## [Cleaning Bank Marketing Campaign Data Project](https://github.com/zaid638/Data-Camp-Projects/tree/main/Cleaning%20Bank%20Marketing%20Campaign%20Data%20Project) <br/><br/>

I have been asked to work with a bank to clean the data they collected as part of a recent marketing campaign, which aimed to get customers to take out a personal loan. They plan to conduct more marketing campaigns going forward so would like you to ensure it conforms to the specific structure and data types that they specify so that they can then use the cleaned data you provide to set up a PostgreSQL database, which will store this campaign's data and allow data from future campaigns to be easily imported. <br/>

### Objective <br/><br/>

* They have supplied me with a csv file called `"bank_marketing.csv"`, which I need to clean, reformat, and split the data, saving three final csv files. <br/><br/>
--- <br/><br/>

## [Data Engineer Associate Exam Virtual Reality Fitness](https://github.com/zaid638/Data-Camp-Projects/tree/main/Cleaning%20the%20Insurance%20Company%20Data%20Project) <br/><br/>

ActiVR provides a virtual reality device designed for exercise and fitness. They offers a range of products, including VR devices and subscription-based fitness programs through their apps. The sales team at ActiVR wants to analyze user data to enhance their marketing strategy and evaluate their products. For this, it is crucial that the data is clean, accurate, and available for reporting.They need assistance in preparing the data before launching a new promotional campaign. <br/><br/>

### Objective <br/><br/>

* Clean the data and present the data in specific type & format. <br/>
* Write SQL quries to prepare some data before they start to run a new promotion. <br/><br/>
--- <br/><br/>

## [Cleaning the Insurance Company Data Project](https://github.com/zaid638/Data-Camp-Projects/tree/main/Cleaning%20the%20Insurance%20Company%20Data%20Projecthttps://github.com/zaid638/Data-Camp-Projects/tree/main/Cleaning%20the%20Insurance%20Company%20Data%20Project) <br/><br/>

I have been given some starting code with two functions: one that extracts and flattens JSON data into a structured format and the other that transforms electricity sales data by cleaning, filtering, and extracting relevant features. The company plans to use my revised code to improve the accuracy of sales analytics. <br/><br/>

### Objective <br/><br/>

* My task is to identify potential errors in the functions and the underlying data that might result in logic and runtime errors, such as missing values, incorrect data types, or incompatible values. Enhanced the custom functions provided by implementing exceptions to catch data quality issues and edge cases. <br/><br/>
--- <br/><br/>

## [Debugging Code](https://github.com/zaid638/Data-Camp-Projects/blob/main/Debugging%20Code/notebook.ipynb) <br/><br/>

Travel Assured provides travel services to its customers. They are based in the United States. They provides everything from flights and hotel bookings to holiday insurance. The sales team wants to sell upgrades to customers. So they can do this, it is vital that the data is clean, accurate and available for reporting. They need help to prepare some data before they start to run a new promotion. <br/><br/>

### Objective <br/><br/>

* Clean the data and present the data in specific type & format. <br/>
* Write SQL quries to prepare some data before they start to run a new promotion. <br/><br/>
--- <br/><br/>

## [Exploring London's Travel Network Project](https://github.com/zaid638/Data-Camp-Projects/tree/main/Exploring%20London's%20Travel%20Network%20Project) <br/><br/>

In this project, I worked with a slightly modified version of a dataset containing information about public transport journey volume by transport type.
The Mayor of London's office make their data available to the public [here](https://data.london.gov.uk/dataset) <br/><br/>

### Objective <br/><br/>

* Find most popular transport types.<br/>
* Find the Emirates airline transport type popularity trend.<br/>
* Find the least popular years of Underground & DLR transport type.<br/><br/><br/><br/>
